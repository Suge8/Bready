import React, { useState, useEffect, useRef, useCallback } from 'react'
import { Send, RefreshCw, Mic, Volume2, X, AlertCircle, CheckCircle, XCircle, Loader2, Wifi, WifiOff, Copy, Check } from 'lucide-react'
import ReactMarkdown from 'react-markdown'
import remarkGfm from 'remark-gfm'
import rehypeHighlight from 'rehype-highlight'
import { Button } from './ui/button'
import { Card, CardContent } from './ui/card'
import { ToastNotification, ConfirmationDialog } from './ui/notifications'
import { TouchButton } from './ui/touch-optimized'
import 'highlight.js/styles/github.css'
import { useI18n } from '../contexts/I18nContext'
import { Modal } from './ui/Modal'
import CollaborationHeader from './collaboration/CollaborationHeader'
import CollaborationSidebar from './collaboration/CollaborationSidebar'

interface CollaborationModeProps {
  onExit: () => void
}

const CollaborationMode: React.FC<CollaborationModeProps> = ({ onExit }) => {
  const { t } = useI18n()
  const isMac = typeof navigator !== 'undefined' && /mac/i.test(navigator.platform)
  // çŠ¶æ€ç®¡ç†
  const [inputText, setInputText] = useState('')
  const [status, setStatus] = useState(t('collaboration.status.initializing'))
  const [isConnected, setIsConnected] = useState(false)
  const [conversationHistory, setConversationHistory] = useState<Array<{ type: 'user' | 'ai', content: string, timestamp: Date, source: 'voice' | 'text' }>>([])
  const [isWaitingForAI, setIsWaitingForAI] = useState(false)
  const [currentVoiceInput, setCurrentVoiceInput] = useState('')
  const [currentAIResponse, setCurrentAIResponse] = useState('')
  const [isComposing, setIsComposing] = useState(false)
  const [showExitConfirm, setShowExitConfirm] = useState(false)
  const [currentAudioMode, setCurrentAudioMode] = useState<'system' | 'microphone'>('system')
  const [showAudioModeDropdown, setShowAudioModeDropdown] = useState(false)
  const [currentError, setCurrentError] = useState<{ type: string, message: string } | null>(null)
  const [isInitializing, setIsInitializing] = useState(true)
  const [toast, setToast] = useState<{ message: string; type: 'success' | 'error' | 'info' | 'warning' } | null>(null)
  const [showConfirmationDialog, setShowConfirmationDialog] = useState<{
    title: string;
    message: string;
    onConfirm: () => void
  } | null>(null)
  const [showPermissionsModal, setShowPermissionsModal] = useState(false)
  const [copySuccess, setCopySuccess] = useState(false)
  const [currentMicrophoneDeviceId, setCurrentMicrophoneDeviceId] = useState<string>('')

  // å¤åˆ¶æ–‡æœ¬åˆ°å‰ªè´´æ¿
  const copyToClipboard = async (text: string) => {
    try {
      await navigator.clipboard.writeText(text)
      setCopySuccess(true)
      setTimeout(() => setCopySuccess(false), 2000)
    } catch (err) {
      console.error('å¤åˆ¶å¤±è´¥:', err)
    }
  }

  // ä½¿ç”¨ ref é˜²æ­¢ React StrictMode å¯¼è‡´çš„é‡å¤åˆå§‹åŒ–
  const hasInitialized = useRef(false)
  const sessionReadyRef = useRef(false)
  const audioStartPendingRef = useRef(false)
  const audioStartedRef = useRef(false)
  const pendingUserInputRef = useRef<{ content: string, source: 'text' } | null>(null)
  const currentVoiceInputRef = useRef('')
  const currentAIResponseRef = useRef('')
  const lastAIResponseRef = useRef('')
  const messagesEndRef = useRef<HTMLDivElement>(null)
  const messagesContainerRef = useRef<HTMLDivElement>(null)
  const rootRef = useRef<HTMLDivElement>(null)
  const currentMicrophoneDeviceIdRef = useRef('')


  // æƒé™çŠ¶æ€
  const [systemPermissions, setSystemPermissions] = useState({
    screenRecording: { granted: false, canRequest: true, message: '' },
    microphone: { granted: false, canRequest: true, message: '' },
    apiKey: { granted: false, canRequest: true, message: '' },
    audioDevice: { granted: false, canRequest: true, message: '' }
  })

  // éŸ³é¢‘æ¨¡å¼é€‰é¡¹
  const audioModeOptions = [
    {
      value: 'system' as const,
      label: t('collaboration.audioMode.system.label'),
      icon: <Volume2 className="w-4 h-4" />,
      description: t('collaboration.audioMode.system.description')
    },
    {
      value: 'microphone' as const,
      label: t('collaboration.audioMode.microphone.label'),
      icon: <Mic className="w-4 h-4" />,
      description: t('collaboration.audioMode.microphone.description')
    }
  ]

  // é”™è¯¯æ ‡é¢˜æ˜ å°„
  const getErrorTitle = (errorType: string) => {
    switch (errorType) {
      case 'api-connection-failed':
        return t('collaboration.errors.apiConnectionFailed')
      case 'audio-device-error':
        return t('collaboration.errors.audioDeviceError')
      case 'permissions-not-set':
        return t('collaboration.errors.permissionsNotSet')
      case 'network-error':
        return t('collaboration.errors.networkError')
      case 'unknown-error':
        return t('collaboration.errors.unknownError')
      default:
        return t('collaboration.errors.unknownError')
    }
  }

  // çŠ¶æ€å›¾æ ‡
  const getStatusIcon = (status: any) => {
    if (status.granted) {
      return <CheckCircle className="w-5 h-5 text-green-500" />
    } else if (status.canRequest) {
      return <AlertCircle className="w-5 h-5 text-yellow-500" />
    } else {
      return <XCircle className="w-5 h-5 text-red-500" />
    }
  }

  // çŠ¶æ€æ–‡æœ¬
  const getStatusText = (status: any) => {
    if (status.granted) return t('collaboration.permissions.granted')
    if (status.canRequest) return t('collaboration.permissions.needsSetup')
    return t('collaboration.permissions.denied')
  }

  // éŸ³é¢‘æ¨¡å¼åˆ‡æ¢å¤„ç†
  const handleAudioModeChange = async (newMode: 'system' | 'microphone') => {
    console.log('ğŸ§ åˆ‡æ¢éŸ³é¢‘æ¨¡å¼:', currentAudioMode, '->', newMode)
    const modeLabel = newMode === 'system'
      ? t('collaboration.audioMode.system.label')
      : t('collaboration.audioMode.microphone.label')

    if (newMode === currentAudioMode) {
      setShowAudioModeDropdown(false)
      return
    }

    setCurrentAudioMode(newMode)
    setShowAudioModeDropdown(false)

    // åœ¨ Electron ç¯å¢ƒä¸­æ›´æ–°éŸ³é¢‘è®¾ç½®
    if (window.bready && isConnected) {
      try {
        setStatus(t('collaboration.status.switchingAudio'))

        // ä½¿ç”¨æ–°çš„ API ç›´æ¥åˆ‡æ¢æ¨¡å¼
        const success = await window.bready.switchAudioMode(newMode)

        if (success) {
          setStatus(t('collaboration.status.switched', { mode: modeLabel }))

          // 2ç§’åæ¢å¤æ­£å¸¸çŠ¶æ€
          setTimeout(() => {
            if (isConnected) {
              setStatus(t('collaboration.status.ready'))
            }
          }, 2000)
        } else {
          setStatus(t('collaboration.status.switchFailed'))
          setCurrentError({
            type: 'audio-device-error',
            message: t('collaboration.errors.audioSwitchFailed', { mode: modeLabel })
          })
        }
      } catch (error) {
        console.error('éŸ³é¢‘æ¨¡å¼åˆ‡æ¢å¤±è´¥:', error)
        setStatus(t('collaboration.status.switchFailed'))
        setCurrentError({
          type: 'audio-device-error',
          message: t('collaboration.errors.audioSwitchError')
        })
      }
    } else {
      // æµè§ˆå™¨æ¨¡å¼ä¸‹çš„æ¨¡æ‹Ÿåˆ‡æ¢
      setStatus(t('collaboration.status.browserSwitched', { mode: modeLabel }))
      setTimeout(() => {
        setStatus(t('collaboration.status.browserPreview'))
      }, 2000)
    }
  }

  const handleMicrophoneDeviceChange = useCallback(async (deviceId: string, label: string) => {
    console.log('ğŸ¤ ç”¨æˆ·æ‰‹åŠ¨åˆ‡æ¢éº¦å…‹é£è®¾å¤‡:', label, deviceId)

    // åŒæ­¥æ›´æ–° state å’Œ ref
    const previousDeviceId = currentMicrophoneDeviceIdRef.current
    setCurrentMicrophoneDeviceId(deviceId)
    currentMicrophoneDeviceIdRef.current = deviceId

    let switchSuccess = true
    try {
      const capture = (window as any).rendererAudioCapture
      if (capture?.setMicrophoneDevice) {
        switchSuccess = await capture.setMicrophoneDevice(deviceId)
      }
    } catch (error) {
      console.error('åˆ‡æ¢éº¦å…‹é£è®¾å¤‡å¤±è´¥:', error)
      switchSuccess = false
    }

    if (!switchSuccess) {
      if (previousDeviceId) {
        setCurrentMicrophoneDeviceId(previousDeviceId)
        currentMicrophoneDeviceIdRef.current = previousDeviceId
      }
      setToast({
        message: 'åˆ‡æ¢éº¦å…‹é£è®¾å¤‡å¤±è´¥',
        type: 'error'
      })
      return
    }

    if (window.bready && isConnected && currentAudioMode === 'microphone') {
      setToast({
        message: t('collaboration.toasts.deviceSwitched', { device: label }),
        type: 'success'
      })
    }
  }, [currentAudioMode, isConnected, t])

  // æƒé™æ£€æŸ¥
  const checkPermissions = async () => {
    try {
      console.log('ğŸ” å¼€å§‹æ£€æŸ¥ç³»ç»Ÿæƒé™...')
      setStatus(t('collaboration.status.checkingPermissions'))

      // æ£€æŸ¥æ˜¯å¦åœ¨ Electron ç¯å¢ƒä¸­
      if (!window.bready) {
        console.log('ğŸŒ æµè§ˆå™¨æ¨¡å¼ - è·³è¿‡æƒé™æ£€æŸ¥')
        setIsInitializing(false)
        setStatus(t('collaboration.status.browserPreview'))
        return
      }

      // è°ƒç”¨ä¸»è¿›ç¨‹æƒé™æ£€æŸ¥
      const permissions = await window.bready.checkPermissions()
      console.log('ğŸ” æƒé™æ£€æŸ¥ç»“æœ:', permissions)

      setSystemPermissions(permissions)

      // æ£€æŸ¥æ‰€æœ‰æƒé™æ˜¯å¦å·²æˆäºˆ
      const allGranted = permissions.screenRecording.granted &&
        permissions.microphone.granted &&
        permissions.apiKey.granted &&
        permissions.audioDevice.granted

      if (!allGranted) {
        console.log('âŒ æƒé™æœªå®Œå…¨æˆäºˆ')
        setStatus(t('collaboration.status.permissionsIncomplete'))
        setCurrentError({
          type: 'permissions-not-set',
          message: t('collaboration.errors.permissionsHint')
        })
        setIsInitializing(false)
        return
      }

      console.log('âœ… æ‰€æœ‰æƒé™å·²æˆäºˆï¼Œåˆå§‹åŒ– AI API')
      setStatus(t('collaboration.status.connecting'))

      // åˆå§‹åŒ– AI API
      await initializeAI()

    } catch (error) {
      console.error('æƒé™æ£€æŸ¥å¤±è´¥:', error)
      setStatus(t('collaboration.status.permissionsFailed'))
      setCurrentError({
        type: 'unknown-error',
        message: `${t('collaboration.status.permissionsFailed')}: ${error instanceof Error ? error.message : String(error)}`
      })
      setIsInitializing(false)
    }
  }

  const startAudioCaptureOnce = async () => {
    if (!window.bready || audioStartedRef.current) {
      return
    }
    audioStartPendingRef.current = false
    setStatus(t('collaboration.status.audioStarting'))
    const audioSuccess = await window.bready.startAudioCapture()
    if (audioSuccess) {
      audioStartedRef.current = true
      setStatus(t('collaboration.status.ready'))
      setIsInitializing(false)
      return
    }
    setIsInitializing(false)
    setCurrentError({
      type: 'audio-device-error',
      message: t('collaboration.errors.audioStartFailed')
    })
    setStatus(t('collaboration.status.audioFailed'))
  }

  // åˆå§‹åŒ– AI API
  const initializeAI = async () => {
    try {
      let apiKey = ''
      sessionReadyRef.current = false
      audioStartPendingRef.current = false
      audioStartedRef.current = false

      // ä»ç¯å¢ƒå˜é‡è·å– API å¯†é’¥
      if (window.env && window.env.GEMINI_API_KEY) {
        apiKey = window.env.GEMINI_API_KEY
      }

      // ä» localStorage è·å–ï¼ˆå¤‡ç”¨ï¼‰
      if (!apiKey) {
        const storedKey = localStorage.getItem('gemini-api-key')
        if (storedKey) {
          apiKey = storedKey
        }
      }

      if (!apiKey) {
        setIsInitializing(false)
        setCurrentError({
          type: 'api-connection-failed',
          message: t('collaboration.errors.apiKeyMissing')
        })
        setStatus(t('collaboration.status.apiKeyMissing'))
        return
      }

      // è·å–é€‰æ‹©çš„å‡†å¤‡é¡¹
      const selectedPreparationStr = localStorage.getItem('bready-selected-preparation')
      let customPrompt = selectedPreparationStr || ''

      let language = localStorage.getItem('bready-selected-language') || 'cmn-CN'
      const purpose = localStorage.getItem('bready-selected-purpose') || 'interview'

      console.log('ğŸ“¤ å‰ç«¯å‡†å¤‡è°ƒç”¨ initializeAIï¼Œå‚æ•°:', {
        customPromptLength: customPrompt.length,
        language,
        purpose
      })

      setStatus(t('collaboration.status.connecting'))
      console.log('ğŸ¤– åˆå§‹åŒ– AI APIï¼ŒAPI å¯†é’¥é•¿åº¦:', apiKey.length)

      // åˆå§‹åŒ– AI è¿æ¥
      const success = await window.bready.initializeAI(apiKey, customPrompt, purpose, language)

      if (success) {
        setIsConnected(true)
        setCurrentError(null)
        audioStartPendingRef.current = true
        setStatus(t('collaboration.status.waitingReady'))

        if (sessionReadyRef.current) {
          await startAudioCaptureOnce()
        }
      } else {
        setIsInitializing(false)
        setCurrentError({
          type: 'api-connection-failed',
          message: t('collaboration.errors.connectFailed')
        })
        setStatus(t('collaboration.status.connectFailed'))
        setToast({ message: t('collaboration.toasts.connectionFailed'), type: 'error' })
        setTimeout(() => {
          onExit()
        }, 800)
      }
    } catch (error) {
      console.error('åˆå§‹åŒ–å¤±è´¥:', error)
      setIsInitializing(false)
      setCurrentError({
        type: 'unknown-error',
        message: `${t('collaboration.status.initFailed')}: ${error instanceof Error ? error.message : String(error)}`
      })
      setStatus(t('collaboration.status.initFailed'))
      setToast({ message: t('collaboration.toasts.connectionFailed'), type: 'error' })
      setTimeout(() => {
        onExit()
      }, 800)
    }
  }

  // é‡è¿å¤„ç†
  const handleReconnect = async () => {
    if (!window.bready) return

    try {
      setStatus(t('collaboration.status.reconnecting'))
      setIsInitializing(true)
      setCurrentError(null)

      console.log('ğŸ”„ å¼€å§‹æ‰‹åŠ¨é‡è¿...')
      const success = await window.bready.manualReconnect()

      if (success) {
        setIsConnected(true)
        setStatus(t('collaboration.status.waitingReady'))
        setCurrentError(null)
        setIsInitializing(false)
        console.log('âœ… æ‰‹åŠ¨é‡è¿æˆåŠŸ')
        audioStartPendingRef.current = true
        audioStartedRef.current = false
        sessionReadyRef.current = false
      } else {
        setIsConnected(false)
        setStatus(t('collaboration.status.reconnectFailedRetry'))
        setIsInitializing(false)
        setCurrentError({
          type: 'api-connection-failed',
          message: t('collaboration.errors.reconnectFailed')
        })
        console.log('âŒ æ‰‹åŠ¨é‡è¿å¤±è´¥')
      }
    } catch (error) {
      console.error('é‡è¿å¤±è´¥:', error)
      setIsConnected(false)
      setStatus(t('collaboration.status.reconnectFailed'))
      setIsInitializing(false)
      setCurrentError({
        type: 'unknown-error',
        message: `${t('collaboration.status.reconnectFailed')}: ${error instanceof Error ? error.message : String(error)}`
      })
    }
  }

  // å‘é€æ¶ˆæ¯å¤„ç†
  const handleSendMessage = async () => {
    if (!inputText.trim()) return

    const messageText = inputText.trim()

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯è®°å½•
    const userMessage = {
      type: 'user' as const,
      content: messageText,
      timestamp: new Date(),
      source: 'text' as const
    }

    setConversationHistory(prev => [...prev, userMessage])

    // è®¾ç½®pendingçŠ¶æ€ï¼Œç”¨äºAIå›å¤æ—¶çš„å†å²è®°å½•å¤„ç†
    pendingUserInputRef.current = {
      content: messageText,
      source: 'text'
    }

    // æ¸…ç©ºè¾“å…¥æ¡†å¹¶è®¾ç½®ç­‰å¾…AIçŠ¶æ€
    setInputText('')
    setIsWaitingForAI(true)

    // é‡ç½®AIå›å¤è®°å½•
    lastAIResponseRef.current = ''

    // æ£€æŸ¥æ˜¯å¦åœ¨ Electron ç¯å¢ƒä¸­
    if (!window.bready) {
      // æµè§ˆå™¨ç¯å¢ƒä¸‹çš„æ¨¡æ‹Ÿå›å¤
      setTimeout(() => {
        const aiMessage = {
          type: 'ai' as const,
          content: t('collaboration.previewReply', { message: messageText }),
          timestamp: new Date(),
          source: 'text' as const
        }
        setConversationHistory(prev => [...prev, aiMessage])

        setIsWaitingForAI(false)
      }, 1000)
      return
    }

    // æ£€æŸ¥è¿æ¥çŠ¶æ€
    if (!isConnected) {
      const errorMessage = {
        type: 'ai' as const,
        content: t('collaboration.errors.notConnected'),
        timestamp: new Date(),
        source: 'text' as const
      }
      setConversationHistory(prev => [...prev, errorMessage])
      setIsWaitingForAI(false)
      return
    }

    try {
      // å‘é€æ–‡å­—æ¶ˆæ¯åˆ° AI æ¨¡å‹
      console.log('ğŸ“¤ å‘é€æ–‡å­—æ¶ˆæ¯åˆ° AI:', messageText)
      const result = await window.bready.sendTextMessage(messageText)

      if (!result.success) {
        console.error('âŒ å‘é€æ–‡å­—æ¶ˆæ¯åˆ° AI å¤±è´¥:', result.error)
        // æ·»åŠ é”™è¯¯æ¶ˆæ¯åˆ°å¯¹è¯è®°å½•
        const errorMessage = {
          type: 'ai' as const,
          content: t('collaboration.errors.sendFailed', { error: result.error || t('collaboration.errors.tryAgain') }),
          timestamp: new Date(),
          source: 'text' as const
        }
        setConversationHistory(prev => [...prev, errorMessage])
        setIsWaitingForAI(false)
      }
      // å¦‚æœå‘é€æˆåŠŸï¼ŒAI çš„å›å¤ä¼šé€šè¿‡ onAIResponse äº‹ä»¶ç›‘å¬å™¨æ¥æ”¶
    } catch (error) {
      console.error('âŒ å‘é€æ–‡å­—æ¶ˆæ¯é”™è¯¯:', error)
      const errorMessage = {
        type: 'ai' as const,
        content: t('collaboration.errors.sendError'),
        timestamp: new Date(),
        source: 'text' as const
      }
      setConversationHistory(prev => [...prev, errorMessage])
      setIsWaitingForAI(false)
    }
  }

  // é€€å‡ºç¡®è®¤å¤„ç†
  const handleExitConfirm = () => {
    setShowExitConfirm(false)
    onExit()
  }

  // è‡ªåŠ¨æ»šåŠ¨åˆ°æœ€æ–°æ¶ˆæ¯
  useEffect(() => {
    const container = messagesContainerRef.current
    if (!container) return
    container.scrollTo({ top: container.scrollHeight, behavior: 'smooth' })
  }, [conversationHistory, currentVoiceInput, currentAIResponse])

  useEffect(() => {
    if (rootRef.current) {
      rootRef.current.scrollTo({ top: 0, left: 0 })
    }
  }, [])

  // ç»„ä»¶æŒ‚è½½æ—¶åˆå§‹åŒ–
  useEffect(() => {
    // åªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶æ£€æŸ¥æƒé™ï¼ˆé˜²æ­¢ React StrictMode é‡å¤è°ƒç”¨ï¼‰
    if (!hasInitialized.current) {
      hasInitialized.current = true
      checkPermissions()
    }

    // å¦‚æœä¸åœ¨ Electron ç¯å¢ƒä¸­ï¼Œè·³è¿‡äº‹ä»¶ç›‘å¬å™¨è®¾ç½®
    if (!window.bready) {
      console.log('ğŸŒ æµè§ˆå™¨æ¨¡å¼ - è·³è¿‡äº‹ä»¶ç›‘å¬å™¨è®¾ç½®')
      setIsInitializing(false)
      setStatus(t('collaboration.status.browserPreview'))
      return
    }

    // è®¾ç½®äº‹ä»¶ç›‘å¬å™¨ï¼ˆæ¯æ¬¡ mount éƒ½éœ€è¦è®¾ç½®ï¼‰
    const removeStatusListener = window.bready.onStatusUpdate(setStatus)
    const removeTranscriptionListener = window.bready.onTranscriptionUpdate((text) => {
      console.log('ğŸ“ [å‰ç«¯] æ”¶åˆ°è½¬å½•:', text?.substring(0, 30), '| AIå›å¤ä¸­:', !!currentAIResponseRef.current)

      // å¦‚æœ AI æ­£åœ¨å›å¤ä¸­ï¼ˆæœ‰ currentAIResponseï¼‰ï¼Œå¿½ç•¥æ–°çš„è½¬å½•
      if (currentAIResponseRef.current) {
        return
      }

      // æ›´æ–°å½“å‰è¯­éŸ³è¾“å…¥çŠ¶æ€
      if (text && text.trim().length > 0) {
        const trimmedText = text.trim()
        console.log('ğŸ“ [å‰ç«¯] æ›´æ–°è¯­éŸ³è¾“å…¥çŠ¶æ€:', trimmedText.substring(0, 30))
        setCurrentVoiceInput(trimmedText)
        currentVoiceInputRef.current = trimmedText
        setIsWaitingForAI(true)
      }
    })
    const removeAIResponseUpdateListener = window.bready.onAIResponseUpdate((response) => {
      console.log('ğŸ“ [å‰ç«¯] æ”¶åˆ° AI æµå¼æ›´æ–°:', response?.substring(0, 30))
      if (!response.trim()) return
      setCurrentAIResponse(response)
      currentAIResponseRef.current = response
      setIsWaitingForAI(false)
    })
    // æ–°å¢ï¼šè½¬å½•å®Œæˆäº‹ä»¶ç›‘å¬å™¨ - å½“è¯­éŸ³è½¬å½•å®Œæˆæ—¶ï¼Œç«‹å³å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å†å²è®°å½•
    const removeTranscriptionCompleteListener = window.bready.onTranscriptionComplete?.((transcription: string) => {
      console.log('âœ… [å‰ç«¯] æ”¶åˆ°è½¬å½•å®Œæˆäº‹ä»¶:', transcription?.substring(0, 30))

      if (!transcription?.trim()) return

      const timestamp = new Date()

      // ç«‹å³å°†ç”¨æˆ·è¯­éŸ³æ¶ˆæ¯æ·»åŠ åˆ°å†å²è®°å½•
      const userMessage = {
        type: 'user' as const,
        content: transcription.trim(),
        timestamp,
        source: 'voice' as const
      }

      console.log('ğŸ“ [å‰ç«¯] ç«‹å³æ·»åŠ è¯­éŸ³ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²è®°å½•')
      setConversationHistory(prev => [...prev, userMessage])

      // æ¸…ç©ºå½“å‰è¯­éŸ³è¾“å…¥æ˜¾ç¤ºï¼ˆå› ä¸ºå·²ç»æ·»åŠ åˆ°å†å²è®°å½•äº†ï¼‰
      setCurrentVoiceInput('')
      currentVoiceInputRef.current = ''

      // è®¾ç½®ç­‰å¾… AI æ ‡è®°ï¼ˆç”¨äºæ˜¾ç¤º "AIæ­£åœ¨æ€è€ƒ..."ï¼‰
      setIsWaitingForAI(true)

      // æ ‡è®°è¿™æ˜¯è¯­éŸ³è¾“å…¥ï¼ŒAI å›å¤æ—¶åªéœ€æ·»åŠ  AI æ¶ˆæ¯
      pendingUserInputRef.current = {
        content: transcription.trim(),
        source: 'text' // è¿™é‡Œæ ‡è®°ä¸º text ä½†å®é™…ä¸Šæ˜¯ä¸ºäº†è®© AI å›å¤æ—¶çŸ¥é“ç”¨æˆ·æ¶ˆæ¯å·²æ·»åŠ 
      }
    })

    const removeAIResponseListener = window.bready.onAIResponse((response) => {
      console.log('ğŸ¯ å‰ç«¯æ”¶åˆ° AI å›å¤:', response)

      if (!response.trim()) return

      // é˜²é‡å¤æ£€æŸ¥
      if (response === lastAIResponseRef.current) {
        console.log('âš ï¸ è·³è¿‡é‡å¤çš„ AI å›å¤')
        return
      }

      lastAIResponseRef.current = response
      const timestamp = new Date()
      setCurrentAIResponse('')
      currentAIResponseRef.current = ''

      // æ— è®ºæ˜¯æ–‡å­—è¾“å…¥è¿˜æ˜¯è¯­éŸ³è¾“å…¥ï¼ˆé€šè¿‡ transcription-complete äº‹ä»¶å·²æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼‰ï¼Œ
      // ç°åœ¨åªéœ€è¦æ·»åŠ  AI å›å¤
      console.log('ğŸ“ æ·»åŠ  AI å›å¤åˆ°å†å²è®°å½•')

      const aiMessage = {
        type: 'ai' as const,
        content: response,
        timestamp,
        source: pendingUserInputRef.current ? 'text' as const : 'voice' as const
      }

      setConversationHistory(prev => [...prev, aiMessage])
      pendingUserInputRef.current = null
      setCurrentVoiceInput('')
      currentVoiceInputRef.current = ''
      setIsWaitingForAI(false)
    })
    const removeSessionInitializingListener = window.bready.onSessionInitializing((initializing) => {
      if (!initializing) {
        setIsConnected(true)
        setCurrentError(null)
      }
    })
    const removeSessionReadyListener = window.bready.onSessionReady(async () => {
      sessionReadyRef.current = true
      if (audioStartPendingRef.current && !audioStartedRef.current) {
        await startAudioCaptureOnce()
      }
    })
    const removeSessionErrorListener = window.bready.onSessionError((error) => {
      setIsConnected(false)
      setStatus(`${t('collaboration.errors.unknownError')}: ${error}`)
      setCurrentError({
        type: 'unknown-error',
        message: error
      })
    })
    const removeSessionClosedListener = window.bready.onSessionClosed(() => {
      setIsConnected(false)
      setStatus(t('collaboration.status.disconnected'))
      sessionReadyRef.current = false
      audioStartPendingRef.current = false
      audioStartedRef.current = false
      setCurrentError({
        type: 'api-connection-failed',
        message: t('collaboration.errors.audioInterrupted')
      })
    })

    // ç›‘å¬éŸ³é¢‘è®¾å¤‡å˜æ›´äº‹ä»¶
    const removeAudioDeviceChangedListener = window.bready.onAudioDeviceChanged?.((data: { deviceId?: string; deviceLabel?: string }) => {
      console.log('ğŸ¤ è®¾å¤‡å·²åˆ‡æ¢:', data.deviceLabel, data.deviceId)
      const nextId = data.deviceId || ''
      const nextLabel = data.deviceLabel || nextId // å¦‚æœ label ä¸å¯ç”¨ï¼Œè‡³å°‘ç”¨ deviceId

      // åªè¦æœ‰ deviceId å°±æ›´æ–°ï¼Œä¸å¼ºåˆ¶è¦æ±‚ label
      if (!nextId) {
        return
      }

      const previousId = currentMicrophoneDeviceIdRef.current

      currentMicrophoneDeviceIdRef.current = nextId
      setCurrentMicrophoneDeviceId(nextId)

      // åªæœ‰å½“è®¾å¤‡çœŸæ­£æ”¹å˜æ—¶æ‰æ˜¾ç¤º Toast
      if (previousId && previousId !== nextId && nextLabel) {
        setToast({
          message: t('collaboration.toasts.deviceSwitched', { device: nextLabel }),
          type: 'info'
        })
      }
    })

    // è¿”å›æ¸…ç†å‡½æ•°
    return () => {
      // æ¸…ç†äº‹ä»¶ç›‘å¬å™¨
      removeStatusListener()
      removeTranscriptionListener()
      removeAIResponseUpdateListener()
      removeTranscriptionCompleteListener?.()
      removeAIResponseListener()
      removeSessionInitializingListener()
      removeSessionReadyListener()
      removeSessionErrorListener()
      removeSessionClosedListener()
      removeAudioDeviceChangedListener?.()
    }
  }, [])

  return (
    <div ref={rootRef} className="h-screen w-screen overflow-hidden bg-[var(--bready-bg)] text-[var(--bready-text)] flex flex-col relative transition-colors duration-300">
      {/* èƒŒæ™¯å…‰æ™•æ•ˆæœå·²ç§»é™¤ï¼Œç¡®ä¿èƒŒæ™¯è‰²ç»Ÿä¸€ */}
      {/* <div className="absolute inset-0 pointer-events-none">
        <div className="absolute -top-24 left-1/2 -translate-x-1/2 w-[720px] h-[420px] bg-[radial-gradient(circle,_var(--bready-glow)_0%,_transparent_65%)] blur-[120px]" />
        <div className="absolute bottom-[-120px] right-[-60px] w-[360px] h-[280px] bg-[radial-gradient(circle,_var(--bready-glow)_0%,_transparent_70%)] blur-[120px]" />
      </div> */}
      {/* å¤åˆ¶æˆåŠŸæç¤º */}
      {copySuccess && (
        <div className="fixed top-4 right-4 z-[9999] animate-in fade-in slide-in-from-top-2 duration-300">
          <div className="flex items-center gap-2 px-4 py-2 bg-[var(--bready-surface)] border border-[var(--bready-border)] rounded-lg shadow-xl">
            <Check className="w-4 h-4 text-emerald-500" />
            <span className="text-sm text-[var(--bready-text)]">{t('collaboration.copySuccess')}</span>
          </div>
        </div>
      )}

      {/* ==================== é¡¶éƒ¨æ§åˆ¶æ  ==================== */}
      {/* 
        å¤–å±‚å®¹å™¨ï¼š
        - w-full: å æ»¡æ•´ä¸ªå®½åº¦
        - bg-[var(--bready-bg)]: ä½¿ç”¨ä¸»é¢˜èƒŒæ™¯è‰²
        - z-50: é«˜å±‚çº§ï¼Œç¡®ä¿åœ¨å…¶ä»–å…ƒç´ ä¹‹ä¸Š
        - border-b: åº•éƒ¨è¾¹æ¡†
        - flex-shrink-0: ä¸å…è®¸æ”¶ç¼©ï¼Œä¿æŒå›ºå®šé«˜åº¦
        - WebkitAppRegion: 'drag': å…è®¸æ‹–åŠ¨çª—å£ï¼ˆmacOS/Windows çª—å£æ‹–åŠ¨åŒºåŸŸï¼‰
        - paddingTop: macOS ä¸Šç•™å‡º 20px ç©ºé—´ç»™ç³»ç»Ÿçº¢ç»¿ç¯æŒ‰é’®
      */}
      <CollaborationHeader
        isMac={isMac}
        title={t('collaboration.title')}
        status={status}
        isConnected={isConnected}
        audioModeOptions={audioModeOptions}
        currentAudioMode={currentAudioMode}
        showAudioModeDropdown={showAudioModeDropdown}
        onToggleAudioModeDropdown={() => setShowAudioModeDropdown(!showAudioModeDropdown)}
        onAudioModeChange={handleAudioModeChange}
        onOpenPermissions={() => setShowPermissionsModal(true)}
        onExit={() => setShowExitConfirm(true)}
        currentMicrophoneDeviceId={currentMicrophoneDeviceId}
        onMicrophoneDeviceChange={handleMicrophoneDeviceChange}
      />

      {/* ä¸»è¦å†…å®¹åŒºåŸŸ - å·¦å³åˆ†æ å¸ƒå±€ */}
      <div className="flex-1 flex p-4 gap-4 overflow-hidden bg-[var(--bready-bg)]">

        {/* å·¦ä¾§ä¸»åŒºåŸŸ - å®æ—¶é—®ç­” (çº¦3/4å®½åº¦) */}
        <div className="flex-1 flex flex-col min-w-0">
          {/* é”™è¯¯æç¤º */}
          {currentError && !isInitializing && (
            <Card className="mb-4 border-red-200 dark:border-red-800 bg-red-50 dark:bg-red-900/20 rounded-xl animate-in fade-in slide-in-from-top-2 duration-300">
              <CardContent className="p-4">
                <div className="flex items-center justify-between">
                  <div className="flex items-center space-x-2">
                    <AlertCircle className="w-5 h-5 text-red-600 dark:text-red-400" />
                    <span className="font-medium text-red-800 dark:text-red-200">
                      {getErrorTitle(currentError.type)}
                    </span>
                  </div>
                  <button
                    onClick={handleReconnect}
                    className="px-3 py-1 bg-red-100 dark:bg-red-800/30 hover:bg-red-200 dark:hover:bg-red-700/50 text-red-700 dark:text-red-300 rounded-lg text-sm font-medium transition-colors cursor-pointer"
                  >
                    {t('collaboration.actions.reconnect')}
                  </button>
                </div>
                <p className="text-red-700 dark:text-red-300 text-sm mt-2">{currentError.message}</p>
              </CardContent>
            </Card>
          )}

          {/* å®æ—¶é—®ç­”å±•ç¤ºåŒº - å›ºå®šå¸ƒå±€ï¼Œåªæœ‰å†…å®¹åŒºåŸŸåŠ¨æ€å˜åŒ– */}
          <div className="flex-1 flex flex-col overflow-hidden relative">
            {/* ç©ºçŠ¶æ€ - ç»å¯¹å®šä½å±…ä¸­ï¼Œæœ‰æ¶ˆæ¯æ—¶æ·¡å‡º */}
            <div className={`absolute inset-0 flex items-center justify-center transition-all duration-500 ${conversationHistory.length === 0 && !currentVoiceInput.trim() && !currentAIResponse.trim() && !isWaitingForAI ? 'opacity-100 pointer-events-auto' : 'opacity-0 pointer-events-none'}`}>
              <div className="text-center text-[var(--bready-text-muted)]">
                <div className="w-20 h-20 mx-auto mb-6 bg-[var(--bready-surface-2)] rounded-full flex items-center justify-center backdrop-blur-sm animate-pulse">
                  <Mic className="w-10 h-10 text-[var(--bready-text-muted)]" />
                </div>
                <p className="text-lg font-medium text-[var(--bready-text)]">
                  {currentAudioMode === 'system' ? t('collaboration.empty.system') : t('collaboration.empty.microphone')}
                </p>
                <p className="text-sm mt-2 text-[var(--bready-text-muted)]">{t('collaboration.empty.helper')}</p>
              </div>
            </div>

            {/* èŠå¤©å†…å®¹åŒºåŸŸ - ç»å¯¹å®šä½ï¼Œæœ‰æ¶ˆæ¯æ—¶æ˜¾ç¤º */}
            <div ref={messagesContainerRef} className={`absolute inset-0 flex flex-col items-center justify-start pt-6 overflow-y-auto transition-all duration-500 ${conversationHistory.length > 0 || currentVoiceInput.trim() || currentAIResponse.trim() || isWaitingForAI ? 'opacity-100 pointer-events-auto' : 'opacity-0 pointer-events-none'}`}>
              <div className="w-full max-w-3xl space-y-8 px-4 pb-4">
                {/* æœ€æ–°ç”¨æˆ·æé—® - ä»å†å²è®°å½•æˆ–å®æ—¶è¾“å…¥ä¸­è·å– */}
                {(() => {
                  // è·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
                  const latestUserMessage = [...conversationHistory].reverse().find(m => m.type === 'user')
                  const showUserMessage = currentVoiceInput.trim() || latestUserMessage

                  if (!showUserMessage && !isWaitingForAI) return null

                  const userContent = currentVoiceInput.trim() || latestUserMessage?.content || ''
                  const isTranscribing = !!currentVoiceInput.trim()

                  if (!userContent) return null

                  return (
                    <div className="animate-in fade-in slide-in-from-bottom-4 duration-500">
                      <div className="flex items-center gap-3 mb-4">
                        <div className="w-10 h-10 rounded-2xl bg-gradient-to-br from-emerald-400 via-emerald-500 to-teal-600 flex items-center justify-center shadow-lg shadow-emerald-500/40 ring-2 ring-emerald-400/20">
                          <Mic className="w-5 h-5 text-white" />
                        </div>
                        <div className="flex flex-col">
                          <span className="text-sm font-semibold text-[var(--bready-text)]">
                            {isTranscribing ? t('collaboration.labels.transcribing') : t('collaboration.labels.input')}
                          </span>
                          {isTranscribing && (
                            <div className="flex gap-1 mt-1">
                              <div className="w-1.5 h-1.5 bg-emerald-400 rounded-full animate-bounce" />
                              <div className="w-1.5 h-1.5 bg-emerald-400 rounded-full animate-bounce" style={{ animationDelay: '0.15s' }} />
                              <div className="w-1.5 h-1.5 bg-emerald-400 rounded-full animate-bounce" style={{ animationDelay: '0.3s' }} />
                            </div>
                          )}
                        </div>
                      </div>
                      <div className="bg-gradient-to-br from-emerald-500/20 via-emerald-500/10 to-teal-500/15 backdrop-blur-2xl rounded-3xl p-7 border border-emerald-400/40 shadow-2xl shadow-emerald-500/20 relative group/user hover:shadow-emerald-500/30 transition-all duration-300">
                        <div className="absolute inset-0 rounded-3xl bg-gradient-to-br from-emerald-400/5 to-transparent pointer-events-none" />
                        <p className="text-xl text-[var(--bready-text)] leading-relaxed font-medium relative z-10">{userContent}</p>
                        {/* å¤åˆ¶æŒ‰é’® */}
                        <button
                          onClick={() => copyToClipboard(userContent)}
                          className="absolute bottom-4 right-4 p-2.5 bg-emerald-500/15 hover:bg-emerald-500/25 rounded-xl opacity-0 group-hover/user:opacity-100 transition-all duration-200 cursor-pointer hover:scale-105"
                          title={t('collaboration.actions.copy')}
                        >
                          <Copy className="w-4 h-4 text-emerald-600 dark:text-emerald-200" />
                        </button>
                      </div>
                    </div>
                  )
                })()}

                {/* AI å›å¤åŒºåŸŸ */}
                {(() => {
                  // è·å–æœ€æ–°çš„ AI æ¶ˆæ¯
                  const latestAIMessage = [...conversationHistory].reverse().find(m => m.type === 'ai')
                  const showAIMessage = currentAIResponse.trim() || latestAIMessage || isWaitingForAI

                  if (!showAIMessage) return null

                  const aiContent = currentAIResponse.trim() || latestAIMessage?.content || ''
                  const isResponding = !!currentAIResponse.trim()

                  return (
                    <div className="animate-in fade-in slide-in-from-bottom-4 duration-500" style={{ animationDelay: '0.15s' }}>
                      <div className="flex items-center gap-3 mb-4">
                        <div className="w-10 h-10 rounded-2xl bg-gradient-to-br from-amber-400 via-amber-500 to-orange-600 flex items-center justify-center shadow-lg shadow-amber-500/40 ring-2 ring-amber-400/20">
                          <span className="text-base">ğŸ</span>
                        </div>
                        <div className="flex flex-col">
                          <span className="text-sm font-semibold text-[var(--bready-text)]">
                            {isWaitingForAI && !aiContent ? t('collaboration.labels.thinking') : isResponding ? t('collaboration.labels.responding') : t('collaboration.labels.bready')}
                          </span>
                          {(isWaitingForAI || isResponding) && (
                            <div className="flex gap-1 mt-1">
                              <div className="w-1.5 h-1.5 bg-amber-400 rounded-full animate-bounce" />
                              <div className="w-1.5 h-1.5 bg-amber-400 rounded-full animate-bounce" style={{ animationDelay: '0.15s' }} />
                              <div className="w-1.5 h-1.5 bg-amber-400 rounded-full animate-bounce" style={{ animationDelay: '0.3s' }} />
                            </div>
                          )}
                        </div>
                      </div>
                      <div className="bg-[var(--bready-surface)] backdrop-blur-2xl rounded-3xl p-7 border border-[var(--bready-border)] shadow-2xl shadow-black/10 relative group/ai hover:border-[var(--bready-border)] transition-all duration-300">
                        <div className="absolute inset-0 rounded-3xl bg-gradient-to-br from-black/[0.02] to-transparent pointer-events-none" />
                        {aiContent ? (
                          <>
                            <div className="prose prose-lg max-w-none text-[var(--bready-text)] prose-p:text-[var(--bready-text)] prose-p:leading-relaxed prose-headings:text-[var(--bready-text)] prose-strong:text-[var(--bready-text)] prose-em:text-[var(--bready-text-muted)] prose-code:text-amber-500 dark:prose-code:text-amber-300 prose-code:bg-black/5 dark:prose-code:bg-white/10 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded-lg prose-li:text-[var(--bready-text)] prose-a:text-emerald-600 dark:prose-a:text-emerald-300 prose-a:no-underline hover:prose-a:underline relative z-10 dark:prose-invert">
                              <ReactMarkdown
                                remarkPlugins={[remarkGfm]}
                                rehypePlugins={[rehypeHighlight]}
                              >
                                {aiContent}
                              </ReactMarkdown>
                            </div>
                            {/* å¤åˆ¶æŒ‰é’® */}
                            <button
                              onClick={() => copyToClipboard(aiContent)}
                              className="absolute bottom-4 right-4 p-2.5 bg-[var(--bready-surface-2)] hover:bg-[var(--bready-surface-3)] rounded-xl opacity-0 group-hover/ai:opacity-100 transition-all duration-200 cursor-pointer hover:scale-105"
                              title={t('collaboration.actions.copy')}
                            >
                              <Copy className="w-4 h-4 text-[var(--bready-text-muted)]" />
                            </button>
                          </>
                        ) : (
                          <div className="flex items-center gap-4 text-[var(--bready-text)]">
                            <div className="w-6 h-6 border-2 border-[var(--bready-border)] border-t-amber-400 rounded-full animate-spin" />
                            <span className="text-[var(--bready-text-muted)] font-medium">{t('collaboration.aiThinking')}</span>
                          </div>
                        )}
                      </div>
                    </div>
                  )
                })()}

                {/* æ»šåŠ¨ç›®æ ‡å…ƒç´  */}
                <div ref={messagesEndRef} />
              </div>
            </div>
          </div>

          {/* è¾“å…¥åŒºåŸŸ */}
          <div className="pt-4 -mb-2 mt-auto">
            <div className="flex items-center space-x-3">
              <div className="flex-1 relative">
                <input
                  type="text"
                  value={inputText}
                  onChange={(e) => setInputText(e.target.value)}
                  placeholder={t('collaboration.input.placeholder')}
                  className="w-full px-5 py-4 bg-[var(--bready-surface-2)] backdrop-blur-sm border border-[var(--bready-border)] rounded-2xl focus:outline-none focus:ring-2 focus:ring-black/10 dark:focus:ring-white/20 focus:border-[var(--bready-border)] text-[var(--bready-text)] placeholder:text-[var(--bready-text-muted)] text-base transition-all duration-200"
                  onCompositionStart={() => setIsComposing(true)}
                  onCompositionEnd={() => setIsComposing(false)}
                  onKeyDown={(e) => {
                    if (e.key === 'Enter' && !isComposing && inputText.trim()) {
                      e.preventDefault()
                      handleSendMessage()
                    }
                  }}
                />
                {inputText && (
                  <button
                    onClick={() => setInputText('')}
                    className="absolute right-4 top-1/2 transform -translate-y-1/2 text-[var(--bready-text-muted)] hover:text-[var(--bready-text)] cursor-pointer transition-colors"
                  >
                    <X className="w-4 h-4" />
                  </button>
                )}
              </div>
              <TouchButton
                onClick={handleSendMessage}
                disabled={!inputText.trim() || isWaitingForAI}
                className="w-12 h-12 bg-black hover:opacity-90 text-white dark:bg-white dark:text-black rounded-xl flex items-center justify-center disabled:opacity-40 disabled:cursor-not-allowed transition-all duration-200 cursor-pointer hover:scale-105"
              >
                <Send className="w-5 h-5" />
              </TouchButton>
            </div>
            <div className="flex items-center justify-center mt-2 text-[10px] text-[var(--bready-text-muted)]">
              <span>{t('collaboration.input.helper')}</span>
            </div>
          </div>
        </div>

        <CollaborationSidebar
          conversationHistory={conversationHistory}
          copyToClipboard={copyToClipboard}
          t={t}
        />
      </div>

      {/* åˆå§‹åŒ–åŠ è½½çŠ¶æ€ */}
      {
        isInitializing && (
          <div className="fixed inset-0 bg-[var(--bready-bg)] flex items-center justify-center z-[9999]">
            <div className="text-center p-6">
              <div className="w-16 h-16 mx-auto mb-4 relative">
                <div className="absolute inset-0 rounded-full bg-[var(--bready-border)] opacity-50 animate-ping"></div>
                <div className="absolute inset-2 rounded-full bg-[var(--bready-border)] opacity-70 animate-ping" style={{ animationDelay: '0.5s' }}></div>
                <div className="absolute inset-4 rounded-full bg-[var(--bready-surface)] border border-[var(--bready-border)] flex items-center justify-center">
                  <Loader2 className="w-6 h-6 text-[var(--bready-text)] animate-spin" />
                </div>
              </div>
              <h2 className="text-xl font-bold text-[var(--bready-text)] mb-2">{status}</h2>
              <p className="text-[var(--bready-text-muted)]">{t('collaboration.status.preparing')}</p>
            </div>
          </div>
        )
      }

      {/* é€€å‡ºç¡®è®¤å¯¹è¯æ¡† */}
      {showExitConfirm && (
        <Modal
          isOpen
          onClose={() => setShowExitConfirm(false)}
          size="sm"
          className="max-w-sm"
        >
          <div className="text-center">
            <div className="w-12 h-12 bg-red-500/15 rounded-full flex items-center justify-center mx-auto mb-4">
              <AlertCircle className="w-6 h-6 text-red-500" />
            </div>
            <h3 className="text-lg font-semibold text-[var(--bready-text)] mb-2">
              {t('collaboration.exit.title')}
            </h3>
            <p className="text-[var(--bready-text-muted)] mb-6">
              {t('collaboration.exit.description')}
            </p>
            <Button onClick={handleExitConfirm} variant="danger" fullWidth>
              {t('collaboration.exit.confirm')}
            </Button>
          </div>
        </Modal>
      )}

      {/* æƒé™è®¾ç½®æ¨¡æ€æ¡† */}
      {showPermissionsModal && (
        <Modal
          isOpen
          onClose={() => setShowPermissionsModal(false)}
          size="sm"
          className="max-w-md"
        >
          <div className="mb-6">
            <h2 className="text-xl font-bold text-[var(--bready-text)]">
              {t('collaboration.permissions.title')}
            </h2>
          </div>

          <div className="space-y-4">
            <div className="bg-[var(--bready-surface-2)] rounded-lg p-4">
              <div className="flex items-center justify-between mb-3">
                <div className="flex items-center space-x-2">
                  <Volume2 className="w-5 h-5 text-[var(--bready-text-muted)]" />
                  <span className="font-medium text-[var(--bready-text)]">{t('collaboration.permissions.systemAudio')}</span>
                </div>
                <div className="flex items-center space-x-2">
                  {getStatusIcon(systemPermissions.screenRecording)}
                  <span className="text-sm font-medium text-emerald-600 dark:text-emerald-300">
                    {getStatusText(systemPermissions.screenRecording)}
                  </span>
                </div>
              </div>
              <p className="text-sm text-[var(--bready-text-muted)]">{t('collaboration.permissions.systemAudioDesc')}</p>
            </div>

            <div className="bg-[var(--bready-surface-2)] rounded-lg p-4">
              <div className="flex items-center justify-between mb-3">
                <div className="flex items-center space-x-2">
                  <Mic className="w-5 h-5 text-[var(--bready-text-muted)]" />
                  <span className="font-medium text-[var(--bready-text)]">{t('collaboration.permissions.microphone')}</span>
                </div>
                <div className="flex items-center space-x-2">
                  {getStatusIcon(systemPermissions.microphone)}
                  <span className="text-sm font-medium text-emerald-600 dark:text-emerald-300">
                    {getStatusText(systemPermissions.microphone)}
                  </span>
                </div>
              </div>
              <p className="text-sm text-[var(--bready-text-muted)]">{t('collaboration.permissions.microphoneDesc')}</p>
            </div>

            <div className="bg-[var(--bready-surface-2)] rounded-lg p-4">
              <div className="flex items-center justify-between mb-3">
                <div className="flex items-center space-x-2">
                  <Wifi className="w-5 h-5 text-[var(--bready-text-muted)]" />
                  <span className="font-medium text-[var(--bready-text)]">{t('collaboration.permissions.network')}</span>
                </div>
                <div className="flex items-center space-x-2">
                  {isConnected ? (
                    <>
                      <Wifi className="w-5 h-5 text-emerald-500" />
                      <span className="text-sm font-medium text-emerald-500">{t('collaboration.permissions.networkConnected')}</span>
                    </>
                  ) : (
                    <>
                      <WifiOff className="w-5 h-5 text-red-500" />
                      <span className="text-sm font-medium text-red-500">{t('collaboration.permissions.networkDisconnected')}</span>
                    </>
                  )}
                </div>
              </div>
              <p className="text-sm text-[var(--bready-text-muted)]">
                {isConnected ? t('collaboration.permissions.networkConnectedDesc') : t('collaboration.permissions.networkDisconnectedDesc')}
              </p>

              {!isConnected && (
                <Button
                  onClick={handleReconnect}
                  variant="outline"
                  size="sm"
                  className="mt-3 w-full"
                >
                  <RefreshCw className="w-4 h-4 mr-2" />
                  {t('collaboration.permissions.reconnect')}
                </Button>
              )}
            </div>
          </div>
        </Modal>
      )}

      {/* Toasté€šçŸ¥ */}
      {
        toast && (
          <ToastNotification
            message={toast.message}
            type={toast.type}
            onClose={() => setToast(null)}
          />
        )
      }

      {/* ç¡®è®¤å¯¹è¯æ¡† */}
      {
        showConfirmationDialog && (
          <ConfirmationDialog
            title={showConfirmationDialog.title}
            message={showConfirmationDialog.message}
            onConfirm={showConfirmationDialog.onConfirm}
            onCancel={() => setShowConfirmationDialog(null)}
          />
        )
      }
    </div >
  )
}

export default CollaborationMode
